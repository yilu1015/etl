{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07d16ca2",
   "metadata": {},
   "source": [
    "## Citekey Validation\n",
    "\n",
    "A citekey is a structured identifier for archival documents. Format:\n",
    "\n",
    "```\n",
    "<slug>[_s<series>][_y<year>[_<year>]][_v<volume>]\n",
    "```\n",
    "\n",
    "### Examples\n",
    "\n",
    "| Citekey | Meaning |\n",
    "|---------|----------|\n",
    "| `zywxhb_v01` | Zywxhb collection, volume 01 |\n",
    "| `zywxhb_v002` | Zywxhb collection, volume 002 (3-digit for this series) |\n",
    "| `zywxhb_y1900_v01` | Zywxhb, year 1900, volume 01 |\n",
    "| `zywxhb_y1900_1905_v01` | Zywxhb, years 1900-1905, volume 01 |\n",
    "| `zywxhb_s03_v01` | Zywxhb, series 03, volume 01 |\n",
    "\n",
    "### Validation Rules\n",
    "\n",
    "1. **Lowercase only**: `zywxhb_v01` ✓, `ZYWXHB_V01` ✗\n",
    "2. **No hyphens**: `zywxhb_v01` ✓, `zywxhb-v01` ✗\n",
    "3. **Volume padding**:\n",
    "   - `zywxhb`: 2-digit volumes (`v01`, `v02`, ..., `v99`)\n",
    "   - `zywxhb`: 3-digit volumes (`v001`, `v002`, ..., `v999`) [configured in `upload_config.yaml`]\n",
    "4. **Year format**: 4 digits (YYYY)\n",
    "5. **Year ranges**: Must be ascending (`y1900_1905` ✓, `y1905_1900` ✗)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5b47df",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "1. **Python environment** with uv:\n",
    "   ```bash\n",
    "   cd /path/to/etl\n",
    "   uv venv\n",
    "   source .venv/bin/activate\n",
    "   uv pip install -r requirements.txt\n",
    "   ```\n",
    "\n",
    "2. **B2 Credentials** (set as environment variables):\n",
    "   ```bash\n",
    "   export B2_SOURCE_ACCESS_KEY_ID=\"your_app_key_id\"\n",
    "   export B2_SOURCE_SECRET_ACCESS_KEY=\"your_app_key\"\n",
    "   ```\n",
    "\n",
    "3. **Optional overrides** (default values from `config/upload_config.yaml`):\n",
    "   ```bash\n",
    "   export B2_SOURCE_BUCKET=\"cna-sources\"\n",
    "   export B2_SOURCE_REGION=\"us-east-005\"\n",
    "   ```\n",
    "\n",
    "Or create a `.env` file in the project root:\n",
    "```\n",
    "B2_SOURCE_ACCESS_KEY_ID=your_key_id\n",
    "B2_SOURCE_SECRET_ACCESS_KEY=your_secret\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50020948",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "\n",
    "### Upload a single PDF\n",
    "```bash\n",
    "uv run scripts/upload_pdfs.py --input data/sources/2026_project/zywxhb_v01.pdf\n",
    "```\n",
    "\n",
    "### Upload all PDFs from a directory\n",
    "```bash\n",
    "uv run scripts/upload_pdfs.py --input data/sources/2026_project/\n",
    "```\n",
    "\n",
    "### Upload from multiple sources\n",
    "```bash\n",
    "uv run scripts/upload_pdfs.py --input data/sources/2026_project1/ data/sources/2026_project2/ some_file.pdf\n",
    "```\n",
    "\n",
    "### Dry-run (validate without uploading)\n",
    "```bash\n",
    "uv run scripts/upload_pdfs.py --input data/sources/2026_project/ --dry-run\n",
    "```\n",
    "\n",
    "### Custom staging directory\n",
    "```bash\n",
    "uv run scripts/upload_pdfs.py --input data/sources/ --staging ./my_staging/\n",
    "```\n",
    "\n",
    "### Quiet mode (suppress progress output)\n",
    "```bash\n",
    "uv run scripts/upload_pdfs.py --input data/sources/ --quiet\n",
    "```\n",
    "\n",
    "### Skip metadata upload to B2\n",
    "```bash\n",
    "uv run scripts/upload_pdfs.py --input data/sources/ --no-metadata-sync\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbdf825",
   "metadata": {},
   "source": [
    "## How It Works\n",
    "\n",
    "### Step 1: Collect PDFs\n",
    "\n",
    "The script scans input paths for `.pdf` files. It accepts:\n",
    "- **Directories**: recursively searches for PDFs\n",
    "- **Individual files**: single PDF paths\n",
    "- **Mixed**: both directories and files\n",
    "\n",
    "```python\n",
    "pdfs = collect_pdfs(input_paths)\n",
    "# Returns: List of Path objects pointing to all found PDFs\n",
    "```\n",
    "\n",
    "### Step 2: Validate Citekeys\n",
    "\n",
    "Each PDF filename (without extension) is validated as a citekey:\n",
    "\n",
    "```python\n",
    "validate_citekey(\"zywxhb_v01\")  # ✓ Valid\n",
    "validate_citekey(\"ZYWXHB_V01\")  # ✗ Error: must be lowercase\n",
    "validate_citekey(\"zywxhb_v1\")   # ✗ Error: volume must be 2 digits\n",
    "```\n",
    "\n",
    "### Step 3: Normalize Structure\n",
    "\n",
    "PDFs are copied into a standard structure in `staging/`:\n",
    "\n",
    "```\n",
    "staging_normalized/\n",
    "  zywxhb_v01/\n",
    "    zywxhb_v01.pdf\n",
    "  zywxhb_v02/\n",
    "    zywxhb_v02.pdf\n",
    "```\n",
    "\n",
    "This ensures consistent structure regardless of input folder layout.\n",
    "\n",
    "### Step 4: Compute Checksums\n",
    "\n",
    "SHA256 checksum is computed for each PDF:\n",
    "\n",
    "```python\n",
    "checksum = sha256(pdf_path)\n",
    "# Returns: \"a1b2c3d4e5f6...\"\n",
    "```\n",
    "\n",
    "### Step 5: Check Against History\n",
    "\n",
    "Load checksums from all previous completed uploads:\n",
    "\n",
    "```python\n",
    "checksums = load_checksums_from_metadata(metadata_dir)\n",
    "# Returns: {\"zywxhb_v01\": \"abc123...\", \"zywxhb_v02\": \"def456...\"}\n",
    "```\n",
    "\n",
    "**Skip** if checksum matches. **Upload** if new or changed.\n",
    "\n",
    "### Step 6: Upload to B2\n",
    "\n",
    "For each PDF that needs uploading:\n",
    "\n",
    "```\n",
    "s3.upload_file(\n",
    "    local_file=staging/zywxhb_v01/zywxhb_v01.pdf,\n",
    "    bucket=cna-sources,\n",
    "    key=zywxhb_v01/zywxhb_v01.pdf\n",
    ")\n",
    "```\n",
    "\n",
    "B2 bucket structure:\n",
    "```\n",
    "cna-sources/\n",
    "  zywxhb_v01/zywxhb_v01.pdf\n",
    "  zywxhb_v02/zywxhb_v02.pdf\n",
    "  run_metadata/2026-01-01_12-30-45.json\n",
    "```\n",
    "\n",
    "### Step 7: Save Metadata\n",
    "\n",
    "Metadata is saved locally and uploaded to B2:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"job_id\": \"2026-01-01_12-30-45\",\n",
    "  \"timestamp\": \"2026-01-01T12:30:45.123456\",\n",
    "  \"bucket\": \"cna-sources\",\n",
    "  \"status\": \"completed\",\n",
    "  \"citekeys\": {\n",
    "    \"total\": 2,\n",
    "    \"uploaded\": 2,\n",
    "    \"skipped\": 0,\n",
    "    \"list\": [\"zywxhb_v01\", \"zywxhb_v02\"]\n",
    "  },\n",
    "  \"checksums\": {\n",
    "    \"zywxhb_v01\": \"abc123...\",\n",
    "    \"zywxhb_v02\": \"def456...\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Local**: `data/sources/job_metadata/2026-01-01_12-30-45.json`\n",
    "**B2**: `cna-sources/run_metadata/2026-01-01_12-30-45.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f1e2dd",
   "metadata": {},
   "source": [
    "## Common Workflows\n",
    "\n",
    "### Workflow 1: First-time Upload\n",
    "\n",
    "Data worker prepares PDFs in `data/sources/2026_january_batch/`:\n",
    "\n",
    "```bash\n",
    "# Dry-run first to validate\n",
    "uv run scripts/upload_pdfs.py --input data/sources/2026_january_batch/ --dry-run\n",
    "\n",
    "# If validation passes, upload for real\n",
    "uv run scripts/upload_pdfs.py --input data/sources/2026_january_batch/\n",
    "```\n",
    "\n",
    "Result:\n",
    "- PDFs uploaded to `cna-sources/zywxhb_v01/`, etc.\n",
    "- Metadata saved to `data/sources/job_metadata/2026-01-01_12-30-45.json`\n",
    "- Metadata uploaded to `cna-sources/run_metadata/2026-01-01_12-30-45.json`\n",
    "\n",
    "### Workflow 2: Incremental Upload\n",
    "\n",
    "Data worker adds new PDFs to `data/sources/2026_january_batch/`:\n",
    "\n",
    "```bash\n",
    "# Script compares checksums against previous jobs\n",
    "# Only uploads new files\n",
    "uv run scripts/upload_pdfs.py --input data/sources/2026_january_batch/\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "Found 5 PDF(s).\n",
    "Normalizing structure...\n",
    "✓ normalized: zywxhb_v01\n",
    "✓ normalized: zywxhb_v02\n",
    "✓ normalized: zywxhb_v03\n",
    "✓ normalized: zywxhb_v04\n",
    "✓ normalized: zywxhb_v05\n",
    "\n",
    "Uploading PDFs...\n",
    "Uploading PDFs: 25%|██▌ | 2/5 [uploaded=2, skipped=2]\n",
    "\n",
    "Summary: 1 uploaded, 4 skipped.\n",
    "```\n",
    "\n",
    "### Workflow 3: Fix a Corrupted Upload\n",
    "\n",
    "If a file was corrupted on B2 and needs re-uploading:\n",
    "\n",
    "```bash\n",
    "# Simply re-run the upload\n",
    "uv run scripts/upload_pdfs.py --input data/sources/2026_january_batch/\n",
    "\n",
    "# Script detects the checksum matches history and skips\n",
    "# To force re-upload, you'd modify the local PDF or its checksum cache\n",
    "# (This is intentional—prevents accidental re-uploads)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aca1f7",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Settings are in `config/upload_config.yaml`. Key options:\n",
    "\n",
    "```yaml\n",
    "directories:\n",
    "  staging: ./staging_normalized      # Temp folder for normalized PDFs\n",
    "  metadata: data/sources/job_metadata # Where to save job metadata\n",
    "\n",
    "b2:\n",
    "  default_bucket: cna-sources        # B2 bucket name\n",
    "  default_region: us-east-005        # B2 region\n",
    "  default_endpoint_url: https://...  # B2 S3 endpoint\n",
    "\n",
    "citekey_rules:\n",
    "  three_digit_volume_series:\n",
    "    - zywxhb                         # This series uses 3-digit volumes\n",
    "```\n",
    "\n",
    "Override via environment variables:\n",
    "\n",
    "```bash\n",
    "export B2_SOURCE_BUCKET=\"my-bucket\"\n",
    "export B2_SOURCE_REGION=\"eu-central-003\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f63caff",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### Error: Citekey validation failed\n",
    "\n",
    "**Problem**: `zywxhb_V04` (uppercase)\n",
    "```\n",
    "ValueError: zywxhb_V04: citekey must be lowercase\n",
    "```\n",
    "\n",
    "**Solution**: Rename file to `zywxhb_v04.pdf` (lowercase)\n",
    "\n",
    "### Error: Volume must be 3 digits\n",
    "\n",
    "**Problem**: `zywxhb_v4` for the zywxhb series\n",
    "```\n",
    "ValueError: zywxhb_v4: volume must be 3 digits for series 'zywxhb'\n",
    "```\n",
    "\n",
    "**Solution**: Rename to `zywxhb_v004.pdf` (3 digits)\n",
    "\n",
    "### Error: B2 configuration incomplete\n",
    "\n",
    "**Problem**: Missing B2 credentials\n",
    "```\n",
    "❌ B2 source configuration incomplete. Required: B2_SOURCE_ACCESS_KEY_ID, ...\n",
    "```\n",
    "\n",
    "**Solution**: Set environment variables or `.env` file:\n",
    "```bash\n",
    "export B2_SOURCE_ACCESS_KEY_ID=\"your_key\"\n",
    "export B2_SOURCE_SECRET_ACCESS_KEY=\"your_secret\"\n",
    "```\n",
    "\n",
    "### Error: No PDFs found\n",
    "\n",
    "**Problem**: Input directory doesn't contain `.pdf` files\n",
    "\n",
    "**Solution**: Check path and ensure files end in `.pdf`\n",
    "\n",
    "### Duplicated uploads\n",
    "\n",
    "**Problem**: Same citekey in staging directory\n",
    "```\n",
    "RuntimeError: Duplicate PDF for citekey zywxhb_v01\n",
    "```\n",
    "\n",
    "**Solution**: Ensure input directory doesn't have duplicate PDFs with same name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5312bc1a",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "### For Data Workers\n",
    "\n",
    "1. **Organize by batch**: Create folders like `data/sources/2026_january/`, `data/sources/2026_february/`\n",
    "2. **Use valid citekeys**: Follow the naming convention strictly\n",
    "3. **Always dry-run first**: Use `--dry-run` to validate before uploading\n",
    "4. **Document your work**: Note which batch you uploaded and when\n",
    "\n",
    "### For Developers\n",
    "\n",
    "1. **Test with small files**: Use `tests/fixtures/sample_pdfs/` for testing, not `data/sources/`\n",
    "2. **Keep metadata**: Don't delete `data/sources/job_metadata/` — it's your audit trail\n",
    "3. **Check job history**: Look at metadata JSON to see what was uploaded when\n",
    "4. **Monitor B2 costs**: Large uploads consume bandwidth; plan batches accordingly\n",
    "\n",
    "### For the Pipeline\n",
    "\n",
    "1. **Staging directory is temporary**: Gets deleted after upload; don't store important files there\n",
    "2. **Checksums are immutable**: Once uploaded with checksum X, same file won't re-upload\n",
    "3. **Metadata is versioned**: Each upload creates a new metadata file with ISO timestamp\n",
    "4. **B2 is source of truth**: Local metadata is a mirror for fast access"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
